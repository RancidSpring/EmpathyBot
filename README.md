# EmpathyBot
Pepper robot emotion recognition and corresponding gesture reaction

# Goals for Development
- **Face recognition**: use OpenCV or similar (do research)
- **Find and implement suitable emotion recognition model**: use pytorch (do research on the model to use)
- **Investigate naoqi**: find out the parameters of the photos from the Pepper
- **Think of the way empathy is translated to gesture**: what is a best answer to the specific emotion. Introduce a set of gestures.
- **Code the movements**: transfer gestures to the code driven the robot's movements 

# Useful links
* A similar implementation of one of my friends (it is simple, but we can use it for the start): https://github.com/PeterKillerio/Neural_Networks/tree/master/Tensorflow/Emotion_recognition
* Here's a video of how it works (the result of the project above):
https://www.youtube.com/watch?v=PdgOubpjWac&ab_channel=PeterBas%C3%A1r
* One of many tutorials for face detection and recognition with OpenCV:
https://www.pyimagesearch.com/2018/09/24/opencv-face-recognition/
* Dataset that contains black&white photos of facial expressions. Later can be used for training:
https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data
* A tutorial on face detection using OpenCV:
https://www.youtube.com/watch?v=mPCZLOVTEc4&ab_channel=TechWithTim
* Emotion recognition overview. Just check it, there are some main points such as what can represent emotions in human behavior (facial expressions, pose, gesture, voice, etc.). There's no need to read it carefully though XD:
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7806093/
* A paper with a similar task, there's a robot, it detects facial expressions and outputs its reaction (don't know if it's useful for us):
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8039024

# Authors
**Lev Kisselyov**: https://github.com/RancidSpring

**Daria Fedorova**: https://github.com/amdorra57
